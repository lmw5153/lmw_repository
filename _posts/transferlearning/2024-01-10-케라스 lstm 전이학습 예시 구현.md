# import 


```python
from datasetsforecast.m4 import M4, M4Evaluation
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
import time
```

# pretrain data

- m4 hourly data
- 24주기 window로 나타냄
- (363850, 23) 


```python
df,*_= M4.load(directory='data',group = 'Hourly')

lst = list(set(df.loc[:,'unique_id']))

tt = [df[df.loc[:,'unique_id']==lst[i]].iloc[:,1:4].set_index(['ds']) 
      for i in range(len(lst))]

for l in range(len(tt)):
    for s in range(1, 24):
        tt[l]['shift_{}'.format(s)] = tt[l]['y'].shift(s)
        tt[l]['shift_{}'.format(s)] = tt[l]['y'].shift(s)
        
tt=[tt[i].dropna(axis=0) for i in range(len(tt))]
```


```python
train = np.concatenate([np.array(tt[i].iloc[:,1:]) for i in range(len(tt))])
y = np.concatenate([np.array(tt[i].iloc[:,0]) for i in range(len(tt))]).reshape(-1,1)
```


```python
from sklearn.preprocessing import MinMaxScaler
min_max_scaler1 = MinMaxScaler()

X_scale = min_max_scaler1.fit_transform(train)
y_scale = min_max_scaler1.fit_transform(y)
```

# target data

- 건물의 전력소비량 벡터
- (183579, 23, 1)
- 이중에서 끝에서부터 2400개의 데이터만 활용 (target data의 크기가 훨씬 적다고 보기 위해)


```python
df = pd.read_csv('C:/Users/default.DESKTOP-2ISHQBS/Documents/R/time_ele/train.csv')

arr = df.iloc[:,9] # 전력소비량
date=  pd.to_datetime(df.iloc[:,2]) # 일시

df_= pd.DataFrame({'date':date,
              'ele': arr})

df_ = df_.set_index('date')

from sklearn.preprocessing import MinMaxScaler
min_max_scaler = MinMaxScaler()

df_['mmele'] = min_max_scaler.fit_transform(df_.iloc[:].to_numpy().reshape(-1,1))

df_ = df_.drop(['ele'],axis=1)

for s in range(1, 24):
    df_['shift_{}'.format(s)] = df_['mmele'].shift(s)
    df_['shift_{}'.format(s)] = df_['mmele'].shift(s)

df_ = df_.dropna()

y = df_.iloc[:,[0]] #scaled 

X = df_.iloc[:,1:]

from sklearn.model_selection import train_test_split

x_train,x_test, y_train , y_test = train_test_split(X,y,shuffle=False, test_size=0.1)

x_train_ = x_train.to_numpy().reshape(x_train.shape[0],x_train.shape[1],1)

x_test_ = x_test.to_numpy().reshape(x_test.shape[0],x_test.shape[1],1)
```


```python
x_train_.shape
```




    (183579, 23, 1)



---

# pretrained Keras lstm


```python
from keras.layers import LSTM
from keras.models import Sequential
from keras.layers import Dense
import keras.backend as K
from keras.callbacks import EarlyStopping
```


```python
K.clear_session()
model1 = Sequential() # Sequeatial Model
model1.add(LSTM(24, input_shape=(23, 1),activation='linear')) # (timestep, feature)
model1.add(Dense(64,activation='linear'))
model1.add(Dense(64,activation='linear'))
model1.add(Dense(1)) # output = 1
model1.compile(loss='mean_squared_error', optimizer='adam')
```


```python
np.random.seed(1)
early_stop = EarlyStopping(monitor='loss', patience=1, verbose=1)

model1.fit(X_scale, y_scale, epochs=100,
          batch_size=128, verbose=1, callbacks=[early_stop])

```

    Epoch 1/100
    2843/2843 [==============================] - 14s 4ms/step - loss: 3.2111e-05
    Epoch 2/100
    2843/2843 [==============================] - 13s 4ms/step - loss: 1.1517e-05
    Epoch 3/100
    2843/2843 [==============================] - 13s 4ms/step - loss: 1.1478e-05
    Epoch 4/100
    2843/2843 [==============================] - 13s 4ms/step - loss: 1.1136e-05
    Epoch 5/100
    2843/2843 [==============================] - 13s 5ms/step - loss: 1.0018e-05
    Epoch 6/100
    2843/2843 [==============================] - 13s 5ms/step - loss: 9.1548e-06
    Epoch 7/100
    2843/2843 [==============================] - 13s 5ms/step - loss: 8.9382e-06
    Epoch 8/100
    2843/2843 [==============================] - 13s 4ms/step - loss: 8.6525e-06
    Epoch 9/100
    2843/2843 [==============================] - 13s 4ms/step - loss: 9.0202e-06
    Epoch 9: early stopping
    




    <keras.src.callbacks.History at 0x1a930bbfa90>



---

# no pretrained lstm model

- 전이학습과의 성능 비교를 위한 모델


```python
K.clear_session()
model0 = Sequential() # Sequeatial Model
model0.add(LSTM(24, input_shape=(23, 1),activation='linear')) # (timestep, feature)
model0.add(Dense(64,activation='linear'))
model0.add(Dense(64,activation='linear'))
model0.add(Dense(1)) # output = 1
model0.compile(loss='mean_squared_error', optimizer='adam')
```


```python
early_stop = EarlyStopping(monitor='loss', patience=1, verbose=1)
start_time0 = time.time()
model0.fit(x_train_, y_train, epochs=100,
          batch_size=128, verbose=1, callbacks=[early_stop])
end_time0 = time.time()
```

    Epoch 1/100
    1435/1435 [==============================] - 7s 4ms/step - loss: 1.0103e-04
    Epoch 2/100
    1435/1435 [==============================] - 6s 4ms/step - loss: 9.9928e-05
    Epoch 3/100
    1435/1435 [==============================] - 6s 4ms/step - loss: 9.8200e-05
    Epoch 4/100
    1435/1435 [==============================] - 6s 4ms/step - loss: 9.4331e-05
    Epoch 5/100
    1435/1435 [==============================] - 6s 4ms/step - loss: 9.1324e-05
    Epoch 6/100
    1435/1435 [==============================] - 6s 4ms/step - loss: 9.1050e-05
    Epoch 7/100
    1435/1435 [==============================] - 6s 5ms/step - loss: 8.7164e-05
    Epoch 8/100
    1435/1435 [==============================] - 6s 4ms/step - loss: 8.8788e-05
    Epoch 8: early stopping
    


```python
total_training_time0 = end_time0 - start_time0

print(f"총 학습에 걸린 시간: {total_training_time0} 초")
```

    총 학습에 걸린 시간: 51.45166802406311 초
    

---

# transfer learning1

- base model 전체를 사용, freezing


```python
from tensorflow.keras import layers
from tensorflow.keras import applications
```


```python
for layer in model.layers:
    layer.trainable = False # freezing

model2 = Sequential()
model2.add(model1.layers[0]) # pretrain model inputlayer1
model2.add(model1.layers[1]) # pretrain model hidden layer2
model2.add(model1.layers[2]) # pretrain model hidden layer3
model2.add(layers.Dense(64, activation='linear'))
model2.add(layers.Dense(1, activation='linear'))
model2.compile(loss='mean_squared_error', optimizer='adam')
```


```python
early_stop = EarlyStopping(monitor='loss', patience=1, verbose=1)
start_time1 = time.time()
model2.fit(x_train_[:2400], y_train[:2400], epochs=100,
          batch_size=128, verbose=1, callbacks=[early_stop])
end_time1 = time.time()
```

    Epoch 1/100
    19/19 [==============================] - 0s 5ms/step - loss: 1.5262e-04
    Epoch 2/100
    19/19 [==============================] - 0s 5ms/step - loss: 1.3834e-04
    Epoch 3/100
    19/19 [==============================] - 0s 5ms/step - loss: 1.4026e-04
    Epoch 3: early stopping
    


```python
total_training_time1 = end_time1 - start_time1

print(f"총 학습에 걸린 시간: {total_training_time1} 초")
```

    총 학습에 걸린 시간: 0.31641507148742676 초
    

---

# transfer learning2
- base model layer3 만 사용
- freezing


```python
for layer in model.layers:
    layer.trainable = False # freezing

model3 = Sequential()
model3.add(LSTM(24, input_shape=(23, 1),activation='linear')) # (timestep, feature)
model3.add(Dense(64,activation='linear'))
model3.add(model1.layers[2]) # pretrain model hidden layer3
model3.add(layers.Dense(64, activation='linear'))
model3.add(layers.Dense(1, activation='linear'))
model3.compile(loss='mean_squared_error', optimizer='adam')
```


```python
early_stop = EarlyStopping(monitor='loss', patience=1, verbose=1)
start_time2 = time.time()
model3.fit(x_train_[:2400], y_train[:2400], epochs=100,
          batch_size=128, verbose=1, callbacks=[early_stop])
end_time2 = time.time()
```

    Epoch 1/100
    19/19 [==============================] - 0s 5ms/step - loss: 2.2113e-04
    Epoch 2/100
    19/19 [==============================] - 0s 5ms/step - loss: 1.9829e-04
    Epoch 3/100
    19/19 [==============================] - 0s 5ms/step - loss: 1.8953e-04
    Epoch 4/100
    19/19 [==============================] - 0s 5ms/step - loss: 1.8507e-04
    Epoch 5/100
    19/19 [==============================] - 0s 5ms/step - loss: 1.9091e-04
    Epoch 5: early stopping
    


```python
total_training_time2 = end_time2 - start_time2

print(f"총 학습에 걸린 시간: {total_training_time2} 초")
```

    총 학습에 걸린 시간: 0.49812960624694824 초
    

---

# transfer learning 3
- base model layer3 만 사용
- not freezing


```python
for layer in model.layers:
    layer.trainable = True # freezing

model4 = Sequential()
model4.add(LSTM(24, input_shape=(23, 1),activation='linear')) # (timestep, feature)
model4.add(Dense(64,activation='linear'))
model4.add(model1.layers[2]) # pretrain model hidden layer3
model4.add(layers.Dense(64, activation='linear'))
model4.add(layers.Dense(1, activation='linear'))
model4.compile(loss='mean_squared_error', optimizer='adam')
```


```python
early_stop = EarlyStopping(monitor='loss', patience=1, verbose=1)
start_time3 = time.time()
model4.fit(x_train_[:2400], y_train[:2400], epochs=100,
          batch_size=128, verbose=1, callbacks=[early_stop])
end_time3 = time.time()
```

    Epoch 1/100
    19/19 [==============================] - 0s 5ms/step - loss: 2.6252e-04
    Epoch 2/100
    19/19 [==============================] - 0s 5ms/step - loss: 2.4993e-04
    Epoch 3/100
    19/19 [==============================] - 0s 5ms/step - loss: 2.4211e-04
    Epoch 4/100
    19/19 [==============================] - 0s 5ms/step - loss: 2.3012e-04
    Epoch 5/100
    19/19 [==============================] - 0s 5ms/step - loss: 2.2209e-04
    Epoch 6/100
    19/19 [==============================] - 0s 5ms/step - loss: 2.2668e-04
    Epoch 6: early stopping
    


```python
total_training_time3 = end_time3 - start_time3

print(f"총 학습에 걸린 시간: {total_training_time3} 초")
```

    총 학습에 걸린 시간: 0.8786656856536865 초
    

---

# test


```python
pred0 = model0.predict(x_test_)
pred2 = model2.predict(x_test_)
pred3 = model3.predict(x_test_)
pred4 = model4.predict(x_test_)
```

    638/638 [==============================] - 1s 1ms/step
    638/638 [==============================] - 1s 1ms/step
    638/638 [==============================] - 1s 1ms/step
    638/638 [==============================] - 1s 1ms/step
    


```python
def MSE(y_true, y_pred):
    return np.mean((y_true - y_pred)**2)

print('layer_not_pretrein MSE :',format(MSE(pred0.flatten(),y_test.values.flatten()),'f'))
print('layer_all_freezing MSE :',format(MSE(pred2.flatten(),y_test.values.flatten()),'f'))
print('layer3_use_freezing MSE:',format(MSE(pred3.flatten(),y_test.values.flatten()),'f'))
print('layer3_not_freezing MSE:',format(MSE(pred4.flatten(),y_test.values.flatten()),'f'))
```

    layer_not_pretrein MSE : 0.000033
    layer_all_freezing MSE : 0.000061
    layer3_use_freezing MSE: 0.000084
    layer3_not_freezing MSE: 0.000075
    


```python
n =100
plt.plot(pred0[:n],label = 'pred0_not_pretrain')
plt.plot(pred2[:n],label = 'pred2_layer_all')
plt.plot(pred3[:n],label = 'pred3_layer_3_use',color = 'red')
plt.plot(pred4[:n],label = 'pred4_layer_3_not')
plt.plot(y_test.values.flatten()[:n],label = 'observed',color = 'black')
plt.legend(loc='lower left')
plt.show()
```


    
![png](output_40_0.png)
    


---

# time, MSE table


```python
lst1 = total_training_time0,total_training_time1,total_training_time2,total_training_time3
lst2 = MSE(pred0.flatten(),y_test.values.flatten()),MSE(pred2.flatten(),y_test.values.flatten()),MSE(pred3.flatten(),y_test.values.flatten()),MSE(pred4.flatten(),y_test.values.flatten())
name = ['no_prtrain','all_freezing','3_freezing','3_nofreezing']
```


```python
pd.DataFrame({'time(second)':lst1,
             'MSE':lst2,
             'model':name})
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>time(second)</th>
      <th>MSE</th>
      <th>model</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>51.45167</td>
      <td>0.00003</td>
      <td>no_prtrain</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.31642</td>
      <td>0.00006</td>
      <td>all_freezing</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.49813</td>
      <td>0.00008</td>
      <td>3_freezing</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.87867</td>
      <td>0.00008</td>
      <td>3_nofreezing</td>
    </tr>
  </tbody>
</table>
</div>



- 전이학습으로 학습한 모델은 매우 빠른 학습시간을 보여준다
- 정확성은 pretrain model이 다소 떨어짐
